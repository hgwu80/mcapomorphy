% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fetch.R
\name{fetch}
\alias{fetch}
\title{download many webpages parallelly}
\usage{
fetch(srcs, prefix_url, dest_dir)
}
\arguments{
\item{srcs}{character. would become the names of downloaded files.}

\item{prefix_url}{string. such as \code{'https://en.wikipedia.org/wiki/'},
\code{paste0(prefix_url, query)} gives the url, see \code{mutate} for \code{query}}

\item{dest_dir}{string. such as 'data-raw/wikipedia/'}
}
\value{
\code{NULL}
}
\description{
download many webpages parallelly
}
\details{
only retry for at most \code{getOption('mcapomorphy.max_iterate', 64L)}
times per execute, you may run it again if you still have problems
}
